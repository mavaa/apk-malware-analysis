import json
import os
import re

distinct_classifications = {}
distinct_classifications_flat = []
jsondir = '100_random_jsons/'

for json_filename in os.listdir(jsondir):
    js_data = json.load(open(jsondir + json_filename, "r"))
    analysis_data = js_data["data"]["attributes"]["last_analysis_results"]

    for key in analysis_data:
        category = analysis_data[key]["category"]
        result = analysis_data[key]["result"]
        if category == "malicious":
            if not key in distinct_classifications:
                distinct_classifications[key] = []

            distinct_classifications[key].append(result)
            distinct_classifications_flat.append(result)

# Remove dupes
for key in distinct_classifications:
    distinct_classifications[key] = list(dict.fromkeys(distinct_classifications[key]))

distinct_classifications_flat = list(dict.fromkeys(distinct_classifications_flat))

# Write to json file
def write_json(path, data):
    out_file = open(path, "w")
    out_file.write(json.dumps(data, sort_keys=True, indent=4))
    out_file.close()

# write_json("distinct.json", distinct_classifications)
# write_json("distinct_flat.json", distinct_classifications_flat)


# Count most common words
word_counts = {}
for classification in distinct_classifications_flat:
    # Split classification on non alphanumeric characters
    for class_word in re.split('\W', classification):
        if class_word != "":
            class_word = class_word.lower()
            if class_word in word_counts:
                word_counts[class_word] += 1
            else:
                word_counts[class_word] = 1

# Sort word list by count
word_counts_sorted = []
wc_view = [ (v,k) for k,v in word_counts.items() ]
wc_view.sort(reverse=True) # natively sort tuples by first element
for value,key in wc_view:
    kv = {}
    kv[key] = value
    word_counts_sorted.append(kv)

write_json("word_counts.json", word_counts_sorted)
